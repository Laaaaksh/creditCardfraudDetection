{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tw0OJuDjbpn0"
      },
      "source": [
        "# Here our aim is to detect all the fraudent transactions which occur in the credit card transactions of the customers"
      ],
      "id": "Tw0OJuDjbpn0",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bledEYYgbpn8"
      },
      "source": [
        "# importing all the necessary pacakages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import gridspec"
      ],
      "id": "bledEYYgbpn8",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdDxxYy8cqDs"
      },
      "source": [
        ""
      ],
      "id": "JdDxxYy8cqDs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7FiL9VPcYx2"
      },
      "source": [
        "# loading the dataset , upload the data set on collab itself\n",
        "data = pd.read_csv(\"creditcard.csv\")"
      ],
      "id": "v7FiL9VPcYx2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "npNE_opzbpoA"
      },
      "source": [
        "# understanding the data and observing\n",
        "data.head()"
      ],
      "id": "npNE_opzbpoA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NyJ-tihCbpoC"
      },
      "source": [
        "# describing the data\n",
        "print(data.shape)\n",
        "print(data.describe())"
      ],
      "id": "NyJ-tihCbpoC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d7LIOxDMbpoD"
      },
      "source": [
        "# Determine number of fraud cases in dataset\n",
        "fraud_transac = data[data['Class'] == 1]\n",
        "valid_transac = data[data['Class'] == 0]\n",
        "outerfrac = len(fraud_transac)float(len(valid_transac))\n",
        "print(outerfrac)\n",
        "print('The fraud cases are as follows: {}'.format(len(data[data['Class'] == 1])))\n",
        "print('The valid transaction cases are as follows: {}'.format(len(data[data['Class'] == 0])))"
      ],
      "id": "d7LIOxDMbpoD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TNDL6QywbpoF"
      },
      "source": [
        "print(\"Amount details of the transactions which are fraud\")\n",
        "fraud_transac.Amount.describe()\n",
        "\n",
        "# as we can see the data is highly unbalanced\n",
        "# we aply our model first , if it turns out to be less accurate we balance the data and reapply it"
      ],
      "id": "TNDL6QywbpoF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aOknYfsQbpoH"
      },
      "source": [
        "# furhter printing the details of the transactions which are not fraud\n",
        "\n",
        "print(\"Details of the transactions which are not valid\")\n",
        "valid_transac.Amount.describe()"
      ],
      "id": "aOknYfsQbpoH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "t2dUzBdjbpoJ"
      },
      "source": [
        "# from the above two plots it was very clear that the average money transaction for the fraud one is\n",
        "# more than the normal transactions\n",
        "# Correlation matrix\n",
        "corrmat = data.corr()\n",
        "fig = plt.figure(figsize = (12, 9))\n",
        "sns.heatmap(corrmat, vmax = .8, square = True)\n",
        "plt.show()"
      ],
      "id": "t2dUzBdjbpoJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4a56ArsXbpoM"
      },
      "source": [
        "\n",
        "# dividing the X and the Y from the dataset\n",
        "X = data.drop(['Class'], axis = 1)\n",
        "Y = data[\"Class\"]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "# getting the values for processing \n",
        "# (its a numpy array with no columns)\n",
        "xData = X.values\n",
        "yData = Y.values"
      ],
      "id": "4a56ArsXbpoM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IMVWYL27bpoN"
      },
      "source": [
        "#Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(\n",
        "\t\txData, yData, test_size = 0.2, random_state = 42)\n"
      ],
      "id": "IMVWYL27bpoN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D8GF2ucAbpoO"
      },
      "source": [
        "# here we set up the random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(xTrain, yTrain)\n",
        "# predictions\n",
        "yPred = rfc.predict(xTest)\n"
      ],
      "id": "D8GF2ucAbpoO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dGGxCiWPbpoP"
      },
      "source": [
        "# Evaluating the classifier\n",
        "# printing every score of the classifier\n",
        "# scoring in anything\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "n_outliers = len(fraud_transac)\n",
        "n_errors = (yPred != yTest).sum()\n",
        "print(\"The model is Random Forest classifier\")\n",
        "\n",
        "acc = accuracy_score(yTest, yPred)\n",
        "print(\"The accuracy is {}\".format(acc))\n",
        "\n",
        "prec = precision_score(yTest, yPred)\n",
        "print(\"The precision is {}\".format(prec))\n",
        "\n",
        "rec = recall_score(yTest, yPred)\n",
        "print(\"The recall is {}\".format(rec))\n",
        "\n",
        "f1 = f1_score(yTest, yPred)\n",
        "print(\"The F1-Score is {}\".format(f1))\n",
        "\n",
        "MCC = matthews_corrcoef(yTest, yPred)\n",
        "print(\"The Matthews correlation coefficient is{}\".format(MCC))\n"
      ],
      "id": "dGGxCiWPbpoP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NzvOtClMbpoQ"
      },
      "source": [
        "\n",
        "# after running through the model we visualize the data in the confusion matrix\n",
        "LABELS = ['Normal', 'Fraud']\n",
        "conf_matrix = confusion_matrix(yTest, yPred)\n",
        "plt.figure(figsize =(12, 12))\n",
        "sns.heatmap(conf_matrix, xticklabels = LABELS,\n",
        "\t\t\tyticklabels = LABELS, annot = True, fmt =\"d\");\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()\n"
      ],
      "id": "NzvOtClMbpoQ",
      "execution_count": null,
      "outputs": []
    }
  ]
}